# XG-Boost (XGB)

## R Packages and Setup {-}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(pROC)
library(xgboost)
```


## Introduction

Placeholder.


## Load Data

```{r}
# Load data
train_xgb <- read.csv('../Train Test Set/train_xgb.csv')
test_xgb <- read.csv('../Train Test Set/test_xgb.csv')


train_xgb_x <- train_xgb[, -which(names(train_xgb) == 'obesity_leveloverweight')]
train_xgb_y <- train_xgb$obesity_leveloverweight

test_xgb_x <- test_xgb[, -which(names(test_xgb) == 'obesity_leveloverweight')]
test_xgb_y <- test_xgb$obesity_leveloverweight

# Display statistics
str(train_xgb)
summary(train_xgb)
head(train_xgb)
```


## Model XGB

### Simple XGB

```{r model_xgb, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Set seed for reproducibility
set.seed(12345)

# Build a model
model_xgb <- xgboost(data = as.matrix(train_xgb_x), 
                     label = train_xgb_y,
                     nrounds = 10,
                     objective = 'binary:logistic')
```

```{r model_xgb_summary}
# Display summary
summary(model_xgb)
```

### Tuned XGB

```{r model_xgb_tuned_setup}
# Set seed for reproducibility
set.seed(12345)

# Set up control parameters
ctrl <- trainControl(method = 'cv', 
                     number = 4,
                     verboseIter = TRUE)

# Define the parameter grid
grid <- expand.grid(nrounds = c(100, 250, 500),
                    max_depth = c(3, 6, 9),
                    eta = c(0.01, 0.1, 0.3),
                    gamma = 0,
                    colsample_bytree = 1,
                    min_child_weight=1,
                    subsample=1)

# grid <- expand.grid(nrounds = c(100, 250, 500, 1000),
#                     max_depth = c(3, 6, 9),
#                     eta = c(0.01, 0.1, 0.3),
#                     gamma = c(0, 0.1, 0.2),
#                     colsample_bytree = c(0.7, 0.8, 1),
#                     min_child_weight = c(1, 3, 5),
#                     subsample = c(0.7, 0.8, 1))


# grid <- expand.grid(
#     nrounds = 500,
#     max_depth = 6,
#     eta = c(0.1, 0.3),
#     gamma = 0,
#     colsample_bytree = 1,
#     min_child_weight = 5,
#     subsample = 1
# )
```


```{r model_xgb_tuned, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Tune the model
xgb_tuned <- train(x = as.matrix(train_xgb_x),
                   y = as.factor(train_xgb_y),
                   method = 'xgbTree',
                   trControl = ctrl,
                   tuneGrid = grid)

# Retrieve best model
model_xgb_tuned <- xgb_tuned$finalModel
```

```{r model_xgb_tuned_summary}
# Display summary
print(xgb_tuned)
summary(model_xgb_tuned)
```


## Evaluate XGB

### Simple XGB

```{r evaluate_xgb}
# Make a prediction
prediction_xgb_probability <- predict(model_xgb, as.matrix(test_xgb_x))
prediction_xgb <- ifelse(prediction_xgb_probability > 0.5, 1, 0)
summary(prediction_xgb_probability)

# Perform confusion matrix
cm_xgb <- confusionMatrix(as.factor(prediction_xgb),
                         as.factor(test_xgb_y),
                         positive = '1')
cm_xgb
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_xgb$overall[1], 4)``, sensitivity of ``r round(cm_xgb$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_xgb$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.


```{r}
pred <- ROCR::prediction(prediction_xgb_probability, test_xgb_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")


auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple XG-Boost ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_xgb, echo=FALSE}
# Write to csv
write.csv(prediction_xgb_probability,
          file = '../Predictions/prediction_xgb_probability.csv',
          row.names = FALSE)

# Extract confusion matrix
write.csv(cm_xgb$table,
          file = '../Confusion Matrix/cm_xgb.csv',
          row.names = FALSE)
```

### Tuned XGB

```{r evaluate_xgb_tuned}
# Make a prediction
prediction_xgb_tuned_probability <- predict(model_xgb_tuned, as.matrix(test_xgb_x))
prediction_xgb_tuned <- ifelse(prediction_xgb_tuned_probability > 0.5, 0, 1)
summary(prediction_xgb_tuned_probability)

# Perform confusion matrix
cm_xgb_tuned <- confusionMatrix(as.factor(prediction_xgb_tuned),
                               as.factor(test_xgb_y),
                               positive = '1')
cm_xgb_tuned
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_xgb_tuned$overall[1], 4)``, sensitivity of ``r round(cm_xgb_tuned$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_xgb_tuned$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.


```{r}
pred <- ROCR::prediction(prediction_xgb_tuned_probability, 1-test_xgb_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")


auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Tuned XG-Boost ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_xgb_tuned, echo=FALSE}
# Write to csv
write.csv(prediction_xgb_tuned_probability,
          file = '../Predictions/prediction_xgb_tuned_probability.csv',
          row.names = FALSE)

# Extract confusion matrix
write.csv(cm_xgb_tuned$table,
          file = '../Confusion Matrix/cm_xgb_tuned.csv',
          row.names = FALSE)
```

