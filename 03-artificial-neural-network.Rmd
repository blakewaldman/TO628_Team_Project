# Artificial Neural Network (ANN)

<!-- ## R Packages and Setup {-} -->


```{r load_libraries_03, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(neuralnet)
```


## Introduction

Artificial neural networks (ANN) are often seen as mimicking how our brain functions, allowing them to learn and improve from experiences.

A key advantage of ANN is their ability to identify intricate and complex patterns that logistic regression may struggle with.

In addition, ANN excel at understanding relationships in high-dimensional data, making them a valuable tool for our dataset.

However, it is important to note that ANN generally require substantial training data and computational resources, which can be time-consuming and resource-intensive.

ANN are also considered a black box, offering little insight into why or how they generate prediction outcomes. For interpreting reasons behind obesity based on factors, ANN may not be the best option; instead, tree models would likely be more effective in this regard.


## Load Data

```{r load_data_03}
# Load data
train_ann <- read.csv('Train Test Set/train_ann.csv')
test_ann <- read.csv('Train Test Set/test_ann.csv')

# Display statistics
str(train_ann)
summary(train_ann)
head(train_ann)
```


## Model ANN

### Simple ANN

We will begin by initializing a single neuron (single node) ANN for running a preliminary simple model. Following the completion of this model, we will develop a more complex one consisting of one hidden layer and one neuron.

```{r model_ann_03, cache=TRUE}
# Build a model
model_ann <- neuralnet(
  obesity_leveloverweight ~ .,
  data = train_ann,
  hidden = 1
  )
```

```{r model_ann_summary_03}
# Display summary
summary(model_ann)
```

### Complex ANN

Introducing hidden layers increases computational demands, leading to longer runtimes compared to a simple ANN. However, this added complexity may yield higher accuracy/Kappa values due to a deeper understanding of the dataset with that extra hidden layer.

```{r model_ann_complex_03, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Display summary
model_ann_complex <- neuralnet(
  obesity_leveloverweight ~ .,
  data = train_ann,
  hidden = c(1, 1),
  stepmax = 1e+07
  )
```

```{r model_ann_complex_summary_03}
# Display summary
summary(model_ann_complex)
```


## Evaluate ANN

### Simple ANN

```{r evaluate_ann_03}
# Make a prediction
prediction_ann_probability <- predict(model_ann, test_ann)
prediction_ann <- ifelse(prediction_ann_probability >= 0.5, 1, 0)
summary(prediction_ann_probability)

# Perform confusion matrix
cm_ann <- confusionMatrix(
  as.factor(prediction_ann),
  as.factor(test_ann$obesity_leveloverweight),
  positive = '1'
  )
cm_ann
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_ann$overall[1], 4)``, sensitivity of ``r round(cm_ann$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_ann$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.


```{r plot_auc_ann_03}
# Plot AUC
pred <- ROCR::prediction(
  prediction_ann_probability,
  test_ann$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple ANN ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_ann_probability_03, echo=FALSE}
# write to csv
write.csv(
  prediction_ann_probability,
  file = 'Predictions/prediction_ann_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_ann$table,
  file = 'Confusion Matrix/cm_ann.csv',
  row.names = FALSE
  )
```

### Complex ANN

```{r evaluate_ann_complex_03}
# Make a prediction
prediction_ann_complex_probability <- predict(model_ann_complex, test_ann)
prediction_ann_complex <- ifelse(prediction_ann_complex_probability >= 0.5, 1, 0)
summary(prediction_ann_complex_probability)

# Perform confusion matrix
cm_ann_complex <- confusionMatrix(
  as.factor(prediction_ann_complex),
  as.factor(test_ann$obesity_leveloverweight),
  positive = '1'
  )
cm_ann_complex
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_ann_complex$overall[1], 4)``, sensitivity of ``r round(cm_ann_complex$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_ann_complex$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_ann_complex_03}
# Plot AUC
pred <- ROCR::prediction(
  prediction_ann_complex_probability,
  test_ann$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Complex ANN ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_ann_complex_probability_03, echo=FALSE}
# write to csv
write.csv(
  prediction_ann_complex_probability,
  file = 'Predictions/prediction_ann_complex_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_ann_complex$table,
  file = 'Confusion Matrix/cm_ann_complex.csv',
  row.names = FALSE
  )
```