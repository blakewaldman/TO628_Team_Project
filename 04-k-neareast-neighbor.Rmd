# K-Neareast Neighbor (KNN)

<!-- ## R Packages and Setup {-} -->

```{r load_libraries_04, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(class)
library(ggplot2)
```


## Introduction

Below paragraph is copied from the assignment, we are planning on updating this as we formulate our narrative for the final deliverable:

KNN can be particularly useful for classification tasks as it identifies the closest training samples (neighbors) in feature space relative to a given test instance, and subsequently employs the labels or values of these neighbors to make predictions. however, KNN is highly sensitive to outliers and can easily lead the model to overfit due to noises.

In an attempt to apply two distinct KNN models, we will initiate with a K value equal to the square root of the training set size, which is common practice. Additionally, we will experiment with another K value to assess its potential impact on our model.


## Load Data

```{r load_data_04}
# Load data
train_knn <- read.csv('Train Test Set/train_knn.csv')
test_knn <- read.csv('Train Test Set/test_knn.csv')

train_knn_x <- train_knn[, !names(train_knn) %in% 'obesity_leveloverweight']
train_knn_y <- train_knn[['obesity_leveloverweight']]

test_knn_x <- test_knn[, !names(test_knn) %in% 'obesity_leveloverweight']
test_knn_y <- test_knn[['obesity_leveloverweight']]

# Display statistics
str(train_knn_x)
summary(train_knn_x)
head(train_knn_x)

str(train_knn_y)
summary(train_knn_y)
head(train_knn_y)
```


## Model KNN

### Default KNN

We will use the square root of the number of rows in the train set as an initial value for parameter k. Next, we will employ grid search to optimize our KNN model and examine if we can enhance its accuracy and overall fit.

```{r model_knn_04, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Set seed for reproducibility
set.seed(12345)

# Build a model
model_knn <- knn(
  train = train_knn_x,
  test = test_knn_x,
  cl = train_knn_y,
  k = sqrt(nrow(train_knn_x)),
  prob = TRUE
  )
prediction_knn_probability <- attributes(model_knn)$prob
```

```{r model_knn_summary_04}
# Display summary
summary(model_knn)
```

### Tuned KNN

We will execute a grid search with 10-fold cross validation.

```{r model_knn_tuned_04, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Set seed for reproducibility
set.seed(12345)

# Set up control parameters
ctrl <- trainControl(
  method = 'cv',
  number = 10
  )

# Define the tuning grid
grid <- expand.grid(
  k = seq(1, 20, by = 1)
  )

# Tune the model
knn_tuned <- train(
  x = train_knn_x,
  y = train_knn_y,
  method = 'knn',
  trControl = ctrl,
  tuneGrid = grid
  )

# Store best parameter
best_k <- knn_tuned$bestTune$k

# Build a model
model_knn_tuned <- knn(
  train = train_knn_x,
  test = test_knn_x,
  cl = train_knn_y,
  k = best_k,
  prob = TRUE
  )
```

```{r model_knn_tuned_summary_04}
# Display summary
print(best_k)
summary(model_knn_tuned)
```

According to the results, the optimal value of k is 9.


## Evaluate KNN

### Default KNN

```{r evaluate_knn_04}
# Make a prediction
prediction_knn <- model_knn
prediction_knn_probability <- attributes(prediction_knn)$prob
summary(prediction_knn_probability)

# Perform confusion matrix
cm_knn <- confusionMatrix(
  as.factor(prediction_knn),
  as.factor(test_knn_y),
  positive = '1'
  )
cm_knn
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_knn$overall[1], 4)``, sensitivity of ``r round(cm_knn$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_knn$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_knn_04}
# Plot AUC
pred <- ROCR::prediction(prediction_knn_probability, test_knn_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple KNN ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_knn_probability_04, echo=FALSE}
# Write to csv
write.csv(
  prediction_knn_probability,
  file = 'Predictions/prediction_knn_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_knn$table,
  file = 'Confusion Matrix/cm_knn.csv',
  row.names = FALSE
  )
```


### Tuned KNN

```{r evaluate_knn_tuned_04}
# Make a prediction
prediction_knn_tuned <- model_knn_tuned
prediction_knn_tuned_probability <- attributes(prediction_knn_tuned)$prob
summary(prediction_knn_tuned_probability)

# Perform confusion matrix
cm_knn_tuned <- confusionMatrix(
  as.factor(prediction_knn_tuned),
  as.factor(test_knn_y),
  positive = '1'
  )
cm_knn_tuned
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_knn_tuned$overall[1], 4)``, sensitivity of ``r round(cm_knn_tuned$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_knn_tuned$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_knn_tuned_04}
# Plot AUC
pred <- ROCR::prediction(prediction_knn_tuned_probability, test_knn_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Tuned KNN ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_knn_tuned_probability_04, echo=FALSE}
# Write to csv
write.csv(
  prediction_knn_tuned_probability,
  file = 'Predictions/prediction_knn_tuned_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_knn_tuned$table,
  file = 'Confusion Matrix/cm_knn_tuned.csv',
  row.names = FALSE
  )
```