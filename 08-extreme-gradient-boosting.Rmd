# eXtreme Gradient Boosting (XGB)

<!-- ## R Packages and Setup {-} -->

```{r load_libraries_08, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(pROC)
library(xgboost)
```


## Introduction

XGBoost is a valuable addition to our current data analytics process due to its use of the ensemble method for constructing sequential trees and weak learners to learn from mistakes, ultimately capturing the true outcome more effectively.

We chose to experiment with this model, though it is not required for the course, as we believe its capabilities could significantly improve accuracy compared to other models.

We will construct two models: a basic XGBoost model and a fine-tuned version to prevent overfitting.


## Load Data

```{r load_data_08}
# Load data
train_xgb <- read.csv('Train Test Set/train_xgb.csv')
test_xgb <- read.csv('Train Test Set/test_xgb.csv')

# Split features and predictor
train_xgb_x <- train_xgb[, !names(train_xgb) %in% 'obesity_leveloverweight']
train_xgb_y <- train_xgb[['obesity_leveloverweight']]

test_xgb_x <- test_xgb[, !names(test_xgb) %in% 'obesity_leveloverweight']
test_xgb_y <- test_xgb[['obesity_leveloverweight']]

# Display statistics
str(train_xgb)
summary(train_xgb)
head(train_xgb)
```


## Model XGB

### Simple XGB

```{r model_xgb_08, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Set seed for reproducibility
set.seed(12345)

# Build a model
model_xgb <- xgboost(
  data = as.matrix(train_xgb_x),
  label = train_xgb_y,
  nrounds = 10,
  objective = 'binary:logistic'
  )
```

```{r model_xgb_summary_08}
# Display summary
summary(model_xgb)
```

### Tuned XGB

```{r model_xgb_tuned_setup_08}
# Set seed for reproducibility
set.seed(12345)

# Set up control parameters
ctrl <- trainControl(
  method = 'cv',
  number = 10,
  verboseIter = TRUE
  )

# Define the parameter grid
grid <- expand.grid(
  nrounds = c(100, 250, 500),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1, 0.3),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight=1,
  subsample=1
  )
```


```{r model_xgb_tuned_08, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Tune the model
xgb_tuned <- train(
  x = as.matrix(train_xgb_x),
  y = as.factor(train_xgb_y),
  method = 'xgbTree',
  trControl = ctrl,
  tuneGrid = grid
  )

# Retrieve best model
model_xgb_tuned <- xgb_tuned$finalModel
```

```{r model_xgb_tuned_summary_08}
# Display summary
print(xgb_tuned)
summary(model_xgb_tuned)
```


## Evaluate XGB

### Simple XGB

```{r evaluate_xgb_08}
# Make a prediction
prediction_xgb_probability <- predict(model_xgb, as.matrix(test_xgb_x))
prediction_xgb <- ifelse(prediction_xgb_probability > 0.5, 1, 0)
summary(prediction_xgb_probability)

# Perform confusion matrix
cm_xgb <- confusionMatrix(
  as.factor(prediction_xgb),
  as.factor(test_xgb_y),
  positive = '1'
  )
cm_xgb
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_xgb$overall[1], 4)``, sensitivity of ``r round(cm_xgb$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_xgb$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.


```{r plot_auc_xgb_08}
# Plot AUC
pred <- ROCR::prediction(prediction_xgb_probability, test_xgb_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple XG-Boost ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_xgb_08, echo=FALSE}
# Write to csv
write.csv(
  prediction_xgb_probability,
  file = 'Predictions/prediction_xgb_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_xgb$table,
  file = 'Confusion Matrix/cm_xgb.csv',
  row.names = FALSE
  )
```

### Tuned XGB

```{r evaluate_xgb_tuned_08}
# Make a prediction
prediction_xgb_tuned_probability <- predict(
  model_xgb_tuned,
  as.matrix(test_xgb_x))
prediction_xgb_tuned <- ifelse(prediction_xgb_tuned_probability > 0.5, 0, 1)
summary(prediction_xgb_tuned_probability)

# Perform confusion matrix
cm_xgb_tuned <- confusionMatrix(
  as.factor(prediction_xgb_tuned),
  as.factor(test_xgb_y),
  positive = '1'
  )
cm_xgb_tuned
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_xgb_tuned$overall[1], 4)``, sensitivity of ``r round(cm_xgb_tuned$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_xgb_tuned$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.


```{r plot_auc_xgb_tuned_08}
# Plot AUC
pred <- ROCR::prediction(prediction_xgb_tuned_probability, 1-test_xgb_y)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Tuned XG-Boost ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_xgb_tuned_08, echo=FALSE}
# Write to csv
write.csv(
  prediction_xgb_tuned_probability,
  file = 'Predictions/prediction_xgb_tuned_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_xgb_tuned$table,
  file = 'Confusion Matrix/cm_xgb_tuned.csv',
  row.names = FALSE
  )
```