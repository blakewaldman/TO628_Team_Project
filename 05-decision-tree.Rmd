# Decision Tree (DT)

## R Packages and Setup {-}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(C50)
```


## Introduction

Below paragraph is copied from the assignment, we are planning on updating this as we formulate our narrative for the final deliverable:

A Decision Tree (DT) is a machine learning model that uses a tree structure for decision making based on given features (predictors). It partitions the input space with tests at nodes to output predictions at leaves. One of its strengths is the ability to handle both categorical and numerical data easily. However, DT can overfit training data and may require pruning or adjustments. Therefore, RF or GB often provide better performance.

In our case, DTs are particularly effective for binary classification problems. In this module, we will utilize two DT models: a simple DT and a DT with a cost matrix. Our goal is to improve our modelâ€™s sensitivity through the employment of these trees as they will yield the highest profit given the cost structure discussed earlier.


## Load Data

```{r}
# Load data
train_dt <- read.csv('Train Test Set/train_dt.csv')
test_dt <- read.csv('Train Test Set/test_dt.csv')

# Display statistics
str(train_dt)
summary(train_dt)
head(train_dt)
```


## Model DT

### Simple DT

First, let's construct a DT model without considering the misclassification error cost.

```{r model_dt, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build a model
model_dt <- C5.0(as.factor(obesity_leveloverweight) ~ .,
                 data = train_dt)
```

```{r model_dt_summary}
# Display summary
summary(model_dt)
plot(model_dt)
varImp(model_dt)
```

According to the variable importance chart, BMI is identified as one of the most significant features for making decisions. This makes intuitive sense since BMI and obesity are highly correlated. Age, on the other hand, exhibits an intriguing aspect as it ranks second in importance but noticeably lower than BMI. We suspect that older individuals may be more prone to obesity due to slower metabolism.

### DT with Cost Matrix

Now, we will introduce a cost matrix where misclassifying an individual as not obese when they are actually obese incurs significant business costs. Conversely, incorrectly labeling someone as obese but discovering they are healthy carries less financial consequence.

```{r model_dt_cost, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build cost matrix
cost_matrix_dt <- matrix(c(0, 8, 1, 0), nrow = 2, byrow = TRUE,
                         dimnames = list(Actual = c('0', '1'),
                                         Predicted = c('0', '1')))

# Build a model
model_dt_cost <- C5.0(as.factor(obesity_leveloverweight) ~ .,
                      data = train_dt,
                      costs = cost_matrix_dt)
```

```{r model_dt_cost_summary}
# Display summary
summary(model_dt_cost)
plot(model_dt_cost)
varImp(model_dt_cost)
```

With a cost matrix in place, the variable importance chart now highlights a heavier emphasis on weight as a top feature, including BMI and weight-to-height ratio.

## Evaluate DT

### Simple DT

```{r evaluate_dt}
# Make a prediction
prediction_dt <- predict(model_dt, test_dt)
prediction_dt_prob <- predict(model_dt, test_dt, type="prob")
summary(prediction_dt)

# Perform confusion matrix
cm_dt <- confusionMatrix(as.factor(prediction_dt),
                         as.factor(test_dt$obesity_leveloverweight),
                         positive = '1')
cm_dt
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_dt$overall[1], 4)``, sensitivity of ``r round(cm_dt$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_dt$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r}
pred <- ROCR::prediction(prediction_dt_prob[,2], test_dt$obesity_leveloverweight)
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")


auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple Decision Tree ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_dt, echo=FALSE}
# Write to csv
write.csv(prediction_dt,
          file = 'Predictions/prediction_dt.csv',
          row.names = FALSE)

# Extract confusion matrix
write.csv(cm_dt$table,
          file = 'Confusion Matrix/cm_dt.csv',
          row.names = FALSE)
```

### DT with Cost Matrix

```{r evaluate_dt_cost}
# Make a prediction
prediction_dt_cost <- predict(model_dt_cost, test_dt)


# Perform confusion matrix
cm_dt_cost <- confusionMatrix(as.factor(prediction_dt_cost),
                              as.factor(test_dt$obesity_leveloverweight),
                              positive = '1')
cm_dt_cost
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_dt_cost$overall[1], 4)``, sensitivity of ``r round(cm_dt_cost$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_dt_cost$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r write_prediction_dt_cost, echo=FALSE}
# Write to csv
write.csv(prediction_dt_cost,
          file = 'Predictions/prediction_dt_cost.csv',
          row.names = FALSE)

# Extract confusion matrix
write.csv(cm_dt_cost$table,
          file = 'Confusion Matrix/cm_dt_cost.csv',
          row.names = FALSE)
```

