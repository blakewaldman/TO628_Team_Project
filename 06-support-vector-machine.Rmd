# Support Vector Machine (SVM)

<!-- ## R Packages and Setup {-} -->

```{r load_libraries_06, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(kernlab)
```


## Introduction

Support Vector Machines (SVMs) are algorithms applicable for both classification and regression tasks. Linear (Vanilla Dot) and Radial Basis Function (RBF) kernels are commonly used choices. The Vanilla Dot kernel is simple and effective for linearly separable data, but it cannot handle complex non-linear relationships. RBF transforms the data into a high-dimensional space to model non-linear relationships, but it requires careful tuning for optimal performance.

In our SVM implementation, we will utilize both Vanilla SVM and RBF SVM.


## Load Data

```{r load_data_06}
# Load data
train_svm <- read.csv('Train Test Set/train_svm.csv')
test_svm <- read.csv('Train Test Set/test_svm.csv')

# Display statistics
str(train_svm)
summary(train_svm)
head(train_svm)
```


## Model SVM

### Vanilla SVM

We will begin by implementing a vanilla kernel SVM. We suspect that this may result in lower accuracy compared to RBF due to our dataset's complexity and less straightforward nature.

```{r model_svm_vanilla_06, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build a vanilla model
model_svm_vanilla <- ksvm(
  obesity_leveloverweight ~ .,
  data = train_svm,
  kernel = 'vanilladot'
  )
```

```{r model_svm_vanilla_summary_06}
# Display summary
summary(model_svm_vanilla)
```

### RBF SVM

```{r model_svm_rbf_06, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build a rbf model
model_svm_rbf <- ksvm(
  obesity_leveloverweight ~ .,
  data = train_svm,
  kernel = 'rbfdot'
  )
```

```{r model_svm_rbf_summary_06}
# Display summary
summary(model_svm_rbf)
```


## Evaluate SVM

### Vanilla SVM

```{r evaluate_svm_vanilla_06}
# Make a prediction
prediction_svm_vanilla_probability <- predict(model_svm_vanilla, test_svm)
prediction_svm_vanilla <- ifelse(prediction_svm_vanilla_probability >= 0.5, 1, 0)
summary(prediction_svm_vanilla_probability)

# Perform confusion matrix
cm_svm_vanilla <- confusionMatrix(
  as.factor(prediction_svm_vanilla),
  as.factor(test_svm$obesity_leveloverweight),
  positive = '1'
  )
cm_svm_vanilla
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_svm_vanilla$overall[1], 4)``, sensitivity of ``r round(cm_svm_vanilla$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_svm_vanilla$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_svm_vanilla_06}
# Plot AUC
pred <- ROCR::prediction(
  prediction_svm_vanilla_probability,
  test_svm$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Vanilla SVM ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_svm_vanilla_06, echo=FALSE}
# Write to csv
write.csv(
  prediction_svm_vanilla,
  file = 'Predictions/prediction_svm_vanilla.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_svm_vanilla$table,
  file = 'Confusion Matrix/cm_svm_vanilla.csv',
  row.names = FALSE
  )
```

### RBF SVM

```{r evaluate_svm_rbf_06}
# Make a prediction
prediction_svm_rbf_probability <- predict(model_svm_rbf, test_svm)
prediction_svm_rbf <- ifelse(prediction_svm_rbf_probability >= 0.5, 1, 0)

# Perform confusion matrix
cm_svm_rbf <- confusionMatrix(
  as.factor(prediction_svm_rbf),
  as.factor(test_svm$obesity_leveloverweight),
  positive = '1'
  )
cm_svm_rbf
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_svm_rbf$overall[1], 4)``, sensitivity of ``r round(cm_svm_rbf$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_svm_rbf$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_svm_rbf_06}
pred <- ROCR::prediction(
  prediction_svm_rbf_probability,
  test_svm$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("RBF SVM ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_svm_rbf_06, echo=FALSE}
# Write to csv
write.csv(
  prediction_svm_rbf,
  file = 'Predictions/prediction_svm_rbf.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_svm_rbf$table,
  file = 'Confusion Matrix/cm_svm_rbf.csv',
  row.names = FALSE
  )
```