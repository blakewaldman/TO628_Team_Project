# Logistic Regression (LR)

<!-- ## R Packages and Setup {-} -->

```{r load_libraries_02, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
```


## Introduction

We will begin by employing Logistic Regression (LR) for our initial model as it is a widely used algorithm for binary classification tasks.

It can run quickly and efficiently, making it suitable for calculating the probability of true or false based on the given dataset features.

However, it is important to keep in mind that LR may encounter challenges with complex relationships between features, limiting its performance on higher dimensional datasets compared to other methods such as Random Forest (RF) or XGBoost (XGB).

To further explore the intricacies within our dataset, we will incorporate interaction terms into our LR models.


## Load Data

```{r load_data_02}
# Load data
train_lr <- read.csv('Train Test Set/train_lr.csv')
test_lr <- read.csv('Train Test Set/test_lr.csv')

# Display statistics
str(train_lr)
summary(train_lr)
head(train_lr)
```


## Model LR

### Simple LR

The model we are building here is a simple LR model that utilizes all the features as predictors and considers a binary outcome labeled `obesity_leveloverweight`.

```{r model_lr_02, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build a model
model_lr <- glm(
  obesity_leveloverweight ~ .,
  data = train_lr,
  family = 'binomial'
  )
```

```{r model_lr_summary_02, collapse=TRUE}
# Display summary
summary(model_lr)
```

Based on the logistic regression results, we can make the following observations:

- **Gender**: Being female is significantly associated with a lesser likelihood of being overweight, as the negative coefficient of `-0.31157` suggests. This indicates that, compared to males, females are less likely to be overweight.

- **Age**: Age is a significant predictor, with a positive coefficient of `0.30465`. This means that as age increases, the likelihood of being overweight also increases.

- **Family History of Overweight**: Individuals with a family history of overweight are significantly more likely to be overweight themselves, indicated by the positive coefficient of `2.14091`.

- **Vegetable Consumption**: Higher frequency of vegetable consumption is linked with a lower probability of being overweight, which is demonstrated by the negative coefficient of `-0.15872`.

- **Number of Meals Per Day**: Eating fewer meals per day is associated with a higher chance of being overweight, as shown by the negative coefficient of `-0.60948`.

- **Food Between Meals**: Consuming food frequently between meals has a negligible effect (coefficient of `-0.10316` with a high p-value), but never eating between meals (`coefficient 2.87107`) and sometimes eating between meals (`coefficient 2.10943`) significantly increase the likelihood of being overweight.

- **Water Intake Daily**: Higher daily water intake is associated with a lesser likelihood of being overweight, as indicated by the positive coefficient of `0.91563`.

- **Physical Activity**: Higher frequency of physical activity is correlated with a lower likelihood of being overweight, demonstrated by the negative coefficient of `-0.13055`.

- **Alcohol Consumption**: The analysis shows that individuals who never (`-2.72373`) or sometimes (`-2.18747`) consume alcohol are less likely to be overweight compared to those who more frequently consume alcohol.

- **Transportation Mode**: Using public transportation (`coefficient 1.21311`) or walking (`coefficient 1.00078`) are both significantly associated with a higher likelihood of being overweight. In contrast, using a bike for transportation (`coefficient -1.43488`) slightly reduces the likelihood.

- **Age Group**: Young adults have a marginally less likelihood of being overweight (`coefficient -0.26825` with a p-value close to significant), whereas adults (`coefficient -1.16505`) and seniors (`coefficient -6.03456`) show significantly lower likelihoods compared to the base group, which might be composed of a younger cohort or teenagers.


### Complex LR

```{r model_lr_complex_02, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# Build a model
model_lr_complex <- glm(
  obesity_leveloverweight ~ . + . * .,
  data = train_lr,
  family = 'binomial'
  )
```

```{r model_lr_complex_summary_02, collapse=TRUE}
# Display summary
summary(model_lr_complex)
```

Once we introduced interaction terms, we noticed that both weight and height became significant factors. Due to an excessive number of terms, we will not delve into them individually.

### Stepwise LR

Due to extended runtime issues, we decided against incorporating stepwise Logistic Regression in our project. Please find the code block left commented out below for your reference.

```{r model_lr_step_02, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
# # Build a model
# model_lr_step <- step(
#   model_lr_complex,
#   direction = 'backward'
#   )
```

```{r model_lr_step_summary_02}
# # Display summary
# summary(model_lr_step)
```


## Evaluate LR

### Simple LR

```{r evaluate_lr_02}
# Make a LR prediction
prediction_lr_probability <- predict(
  model_lr,
  newdata = test_lr,
  type = 'response'
  )
prediction_lr <- ifelse(prediction_lr_probability > 0.5, 1, 0)
summary(prediction_lr_probability)

# Perform confusion matrix
cm_lr <- confusionMatrix(
  as.factor(prediction_lr),
  as.factor(test_lr$obesity_leveloverweight),
  positive = '1'
  )
cm_lr
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_lr$overall[1], 4)``, sensitivity of ``r round(cm_lr$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_lr$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_lr_02}
# Plot AUC
pred <- ROCR::prediction(
  prediction_lr_probability,
  test_lr$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Simple Logistic Regression ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_lr_probability_02, echo=FALSE}
# write to csv
write.csv(
  prediction_lr_probability,
  file = 'Predictions/prediction_lr_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_lr$table,
  file = 'Confusion Matrix/cm_lr.csv',
  row.names = FALSE
  )
```

### Complex LR

```{r evaluate_lr_complex_02}
# Make a complex LR prediction
prediction_lr_complex_probability <- predict(
  model_lr_complex,
  newdata = test_lr,
  type = 'response'
  )

attr(prediction_lr_complex_probability, "non-estim")
attr(prediction_lr_complex_probability, "non-estim") <- NULL

prediction_lr_complex <- ifelse(prediction_lr_complex_probability > 0.5, 1, 0)
summary(prediction_lr_complex_probability)

# Perform confusion matrix
cm_lr_complex <- confusionMatrix(
  as.factor(prediction_lr_complex),
  as.factor(test_lr$obesity_leveloverweight),
  positive = '1'
  )
cm_lr_complex
```

Based on the confusion matrix, we observe that the model achieves an accuracy of ``r round(cm_lr_complex$overall[1], 4)``, sensitivity of ``r round(cm_lr_complex$byClass[1], 4)``, and a Kappa coefficient of ``r round(cm_lr_complex$overall[2], 4)``. We will assess these results towards the conclusion of the assignment when we have completed stacked models.

```{r plot_auc_lr_complex_02}
# Plot AUC
pred <- ROCR::prediction(
  prediction_lr_complex_probability,
  test_lr$obesity_leveloverweight
  )
perf <- ROCR::performance(pred, measure = "tpr", x.measure = "fpr")
auc <- ROCR::performance(pred, measure="auc")

auc <- round(auc@y.values[[1]],3)
roc.data <- data.frame(fpr=unlist(perf@x.values),
                       tpr=unlist(perf@y.values),
                       model="GLM")

ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2, fill = "blue") +
    geom_line(aes(y=tpr), col = "blue") +
    geom_abline(intercept = 0, slope = 1, lty = "dashed") +
    labs(title = paste0("Complex Logistic Regression ROC Curve w/ AUC=", auc)) +
    theme_bw()
```

```{r write_prediction_lr_complex_probability_02, echo=FALSE}
# Write to csv
write.csv(
  prediction_lr_complex_probability,
  file = 'Predictions/prediction_lr_complex_probability.csv',
  row.names = FALSE
  )

# Extract confusion matrix
write.csv(
  cm_lr_complex$table,
  file = 'Confusion Matrix/cm_lr_complex.csv',
  row.names = FALSE
  )
```

### Stepwise LR

No evaluation will be conducted since we abandoned running stepwise Logistic Regression.